{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezb9nac6GL-I"
      },
      "source": [
        "## **CNN e Fine-Tuning com WiSARD e HDC**\n",
        "\n",
        "#### **Trabalho de I.A. Verde**\n",
        "#### **Prof.:** Leandro Santiago\n",
        "#### **Equipe:** Alessandra Gomes, Camila Alves, Camila Rocha e Sandy Cabral\n",
        "#### **Neste Notebook:** ####\n",
        "- Implementação da CNN do artigo \"Emotion Recognition in Instrumental Music Using AI\" em **PyTorch**. O artigo está disponível em https://sol.sbc.org.br/index.php/bracis/article/view/33627 e o respectivo repositório em https://github.com/Camila-Ferr/Emotional-Mapping\n",
        "- Dataset disponível em: https://drive.google.com/drive/folders/19wQom3nrmOlWYhUS5Fjy150zbFaIJe_T?usp=drive_link\n",
        "- Implementação de Fine-Tuning com WiSARD e HDC\n",
        "- Comparação entre Métricas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parte 1: Implementação do CNN em PyTorch**\n",
        "\n",
        "A implementação original da CNN do artigo \"Emotion Recognition in Instrumental Music Using AI\" foi feita com Tensorflow. Para a execução do fine-tuning proposto para este trabalho, o código refeito utilizando PyTorch"
      ],
      "metadata": {
        "id": "5QF1b-MGk4Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "from torch import Tensor\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "IJC0kkD42Apo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "wT7pSLnPmbTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2wF8JqmQX5",
        "outputId": "b811d006-cc0a-4f1c-bfdb-a7f6711137b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# atualize com o caminho para o conforme seu drive pessoal\n",
        "spectograms_path = '/content/.../Spectograms'\n",
        "\n",
        "for file in os.listdir(spectograms_path):\n",
        "    print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FFFTPo0mWOm",
        "outputId": "4e66f640-3b8a-4b58-86ba-62e58740b98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy\n",
            "romantic\n",
            "dramatic\n",
            "aggressive\n",
            "sad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# carrega e prepara as imagens para o treinamento\n",
        "def load_images_from_path_pytorch(path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    transform = transforms.Compose([\n",
        "        # redimensiona para o tamanho desejado\n",
        "        transforms.Resize((224, 224)),\n",
        "        # converte para tensor e normaliza para [0,1]\n",
        "        transforms.ToTensor(),\n",
        "        # normalização padrão ImageNet\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    for file in os.listdir(path):\n",
        "        if file.endswith('.png'):\n",
        "            img_path = os.path.join(path, file)\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            img_tensor = transform(img)\n",
        "            images.append(img_tensor)\n",
        "            labels.append(label)\n",
        "\n",
        "    images_tensor = torch.stack(images)\n",
        "    return images_tensor, labels\n"
      ],
      "metadata": {
        "id": "StPiOGYe2bJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = [\"aggressive\", \"dramatic\", \"happy\", \"romantic\", \"sad\"]\n",
        "\n",
        "x_CNN_Aut = []\n",
        "y_CNN_Aut = []\n",
        "\n",
        "# Carregar e armazena em lista as imagens e os rótulos\n",
        "for emotion in emotions:\n",
        "    images, labels = load_images_from_path_pytorch( f\"{spectograms_path}/{emotion}\", emotion)\n",
        "    x_CNN_Aut.extend(images)\n",
        "    y_CNN_Aut.extend(labels)\n",
        "\n",
        "# Converter listas para arrays numpy\n",
        "x_CNN_Aut = np.array(x_CNN_Aut)\n",
        "y_CNN_Aut = np.array(y_CNN_Aut)\n",
        "\n",
        "# Codificar os rótulos da classe target\n",
        "label_encoder = LabelEncoder()\n",
        "y_CNN_Aut_encoded = label_encoder.fit_transform(y_CNN_Aut)\n",
        "\n",
        "# Divisão do dataset em treino e teste\n",
        "x_train_CNN_Aut, x_test_CNN_Aut, y_train_CNN_Aut, y_test_CNN_Aut = train_test_split(x_CNN_Aut, y_CNN_Aut_encoded, stratify=y_CNN_Aut_encoded, test_size=0.2, random_state=0)\n",
        "\n",
        "# Normalização\n",
        "x_train_norm_CNN_Aut = x_train_CNN_Aut / 255.0\n",
        "x_test_norm_CNN_Aut = x_test_CNN_Aut / 255.0\n",
        "\n",
        "# número total de classes do seu problema\n",
        "num_classes = len(emotions)\n",
        "\n",
        "# adaptação dos conjuntos de treino e teste para DataLoader\n",
        "x_train_tensor = torch.tensor(x_train_CNN_Aut, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_CNN_Aut, dtype=torch.long)\n",
        "x_test_tensor = torch.tensor(x_test_CNN_Aut, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_CNN_Aut, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "SgdvmL9Z0jWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hiperparâmetros utilizados no artigo\n",
        "units = 512\n",
        "dropout = 0.30000000000000004\n",
        "learning_rate = 0.0003209523930194174"
      ],
      "metadata": {
        "id": "BoromamoJDml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = models.vgg16(pretrained=True)\n",
        "\n",
        "# congela convoluções\n",
        "for param in vgg.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# customização do classificador vgg\n",
        "num_features = vgg.classifier[0].in_features\n",
        "vgg.classifier = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(num_features, units),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(dropout),\n",
        "    nn.Linear(units, num_classes)\n",
        ")\n",
        "\n",
        "vgg = vgg.to(device)\n",
        "\n",
        "# otimizador e loss\n",
        "optimizer = optim.Adam(vgg.parameters(), lr = learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# loop de treinamento\n",
        "vgg.train()\n",
        "for epoch in range(30):\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# avaliação\n",
        "vgg.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = vgg(images)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5po1g570Den",
        "outputId": "74104033-1f75-46ed-ce76-7f2694986647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:10<00:00, 54.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# métricas obtidas pelo modelo treinado de acordo com o artigo\n",
        "print(classification_report(all_labels, all_preds, target_names=emotions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmNJcOX6qja_",
        "outputId": "6154cd96-8a36-4e68-ac15-dfdfb81d46cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  aggressive       0.94      0.96      0.95       100\n",
            "    dramatic       0.93      0.91      0.92       100\n",
            "       happy       1.00      0.95      0.97       100\n",
            "    romantic       0.86      0.88      0.87       100\n",
            "         sad       0.91      0.94      0.93       100\n",
            "\n",
            "    accuracy                           0.93       500\n",
            "   macro avg       0.93      0.93      0.93       500\n",
            "weighted avg       0.93      0.93      0.93       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# descomentar se necessário\n",
        "\n",
        "# salvar o modelo\n",
        "#torch.save(vgg.state_dict(), 'vgg16_CNN_model_weights.pth')"
      ],
      "metadata": {
        "id": "Kmn9OXappK_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parte 2: Fine-Tuning**"
      ],
      "metadata": {
        "id": "baxoys6SrEjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Última Camada de Convolução**\n",
        "\n",
        "A arquitetura padrão do VGG16 é organizada em dois blocos principais: features e classifier. O bloco de features contém as camadas convolucionais e pooling e o classifier as camadas totalmente conectadas do modelo. O bloco features é o responsável pela extração das características visuais da imagem, logo, será o utilizado na implementação do fine-tuning deste trabalho.\n",
        "\n",
        "A visualização do bloco features do modelo VGG16 mostra que a última camada convolucional é a Conv2d, na posição 28, seguida por uma função de ativação ReLU e uma pooling MaxPool."
      ],
      "metadata": {
        "id": "ymmukvEorHQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T5EwHD-B5j2",
        "outputId": "076968e4-a3a2-4b2c-a8f0-e76d87430c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): ReLU(inplace=True)\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (6): ReLU(inplace=True)\n",
              "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): ReLU(inplace=True)\n",
              "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU(inplace=True)\n",
              "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (13): ReLU(inplace=True)\n",
              "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (15): ReLU(inplace=True)\n",
              "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (18): ReLU(inplace=True)\n",
              "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (20): ReLU(inplace=True)\n",
              "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (22): ReLU(inplace=True)\n",
              "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (25): ReLU(inplace=True)\n",
              "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (27): ReLU(inplace=True)\n",
              "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (29): ReLU(inplace=True)\n",
              "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomentar caso inicie a execução do carregamento do arquivo do modelo\n",
        "\n",
        "# carregar o modelo\n",
        "#model_path = '/content/.../vgg16_CNN_model_weights.pth'\n",
        "\n",
        "#model = models.vgg16()\n",
        "#model.load_state_dict(torch.load(model_path, weights_only=True, strict=False))\n",
        "#model.eval()\n",
        "\n",
        "#vgg = models.vgg16(pretrained=True)\n",
        "#for param in vgg.features.parameters():\n",
        "#    param.requires_grad = False\n",
        "\n",
        "#vgg = vgg.to(device)\n",
        "# modo avaliação, sem treinamento das convoluções\n",
        "#vgg.eval()"
      ],
      "metadata": {
        "id": "f3Yg3lIdgsgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extração do vetor de features da última camada convolucional\n",
        "# x: batch de imagens\n",
        "def extract_features(x):\n",
        "    with torch.no_grad():\n",
        "        # retorna a saída da última camada convolucional (default)\n",
        "        x = vgg.features(x)\n",
        "        # reduz a uma média global espacial em 512x1x1\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        # achatamento do vetor de features para 1D\n",
        "        features = torch.flatten(x, 1)\n",
        "    return features"
      ],
      "metadata": {
        "id": "MF6ouXyK_5fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine-Tuning com Wisard**"
      ],
      "metadata": {
        "id": "AUsDnDmFoRTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instalação do torchwnn\n",
        "!pip install torchwnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es5i-Watoqh8",
        "outputId": "1f228811-a994-47c7-9831-e43eb7e6a624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchwnn\n",
            "  Downloading torchwnn-0.0.0.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchwnn) (2.6.0+cu124)\n",
            "Collecting ucimlrepo (from torchwnn)\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torchwnn) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from torchwnn) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchwnn) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->torchwnn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->torchwnn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->torchwnn) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torchwnn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torchwnn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torchwnn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchwnn)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchwnn)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchwnn)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchwnn)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchwnn)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchwnn)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchwnn)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchwnn)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchwnn)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchwnn)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchwnn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchwnn) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo->torchwnn) (2025.7.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->torchwnn) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchwnn) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m995.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Building wheels for collected packages: torchwnn\n",
            "  Building wheel for torchwnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchwnn: filename=torchwnn-0.0.0-cp311-cp311-linux_x86_64.whl size=2809523 sha256=ef11f6efaa6c6a983df52a9b980deb3faa3e23a23c07d72d83e787d18dc9be08\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/c9/18/61f905fd3699606114893698f287eb7c42ea0a58db07f09ad2\n",
            "Successfully built torchwnn\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, ucimlrepo, nvidia-cusolver-cu12, torchwnn\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchwnn-0.0.0 ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchwnn.classifiers import Wisard\n",
        "from torchwnn.encoding import Thermometer"
      ],
      "metadata": {
        "id": "L4J6mIaKKjfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extração de features para as imagens no conjunto de treinamento\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        features = extract_features(images)\n",
        "    #lista de tensores\n",
        "    all_features.append(features.cpu())\n",
        "    all_labels.append(labels.cpu())\n",
        "\n",
        "# extração de features para as imagens no conjunto de teste\n",
        "all_features_t = []\n",
        "all_labels_t = []\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        features = extract_features(images)\n",
        "    #lista de tensores\n",
        "    all_features_t.append(features.cpu())\n",
        "    all_labels_t.append(labels.cpu())"
      ],
      "metadata": {
        "id": "Ab4YUmKKshj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatena os batches dos dados de treinamento\n",
        "X_train_tensor = torch.cat(all_features, dim=0)\n",
        "y_train_tensor = torch.cat(all_labels, dim=0)\n",
        "\n",
        "print(X_train_tensor.shape)\n",
        "\n",
        "# concatena os batches dos dados de teste\n",
        "X_test_tensor = torch.cat(all_features_t, dim=0)\n",
        "y_test_tensor = torch.cat(all_labels_t, dim=0)\n",
        "\n",
        "print(X_test_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENWTDnZE2TW7",
        "outputId": "86e544ee-1c18-471c-d923-2739ede96367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2000, 512])\n",
            "torch.Size([500, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# codificação com Termômetro\n",
        "bits_encoding = 16\n",
        "encoding = Thermometer(bits_encoding).fit(X_train_tensor)\n",
        "X_train_bin = encoding.binarize(X_train_tensor).flatten(start_dim=1)\n",
        "\n",
        "encoding2 = Thermometer(bits_encoding).fit(X_test_tensor)\n",
        "X_test_bin = encoding2.binarize(X_test_tensor).flatten(start_dim=1)"
      ],
      "metadata": {
        "id": "IFSRlrvptLfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# treinamento do modelo Wisard e predição\n",
        "\n",
        "entry_size = X_train_bin.shape[1]\n",
        "tuple_size = 32\n",
        "\n",
        "y_train_tensor = y_train_tensor.to(torch.int32)\n",
        "X_train_bin = X_train_bin.to(torch.int32)\n",
        "\n",
        "model_w = Wisard(entry_size, num_classes, tuple_size)\n",
        "model_w.fit(X_train_bin, y_train_tensor)\n",
        "\n",
        "predictions_w = model_w.predict(X_test_bin)\n",
        "predictions_w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYw64ZdP2sbG",
        "outputId": "6bcfacc5-a4b1-40a0-cb68-cf5c758bcefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 1, 2, 0, 3, 2, 1, 4, 1, 3, 2, 0, 0, 2, 3, 2, 3, 4, 2, 1, 0, 2, 0, 1,\n",
              "        2, 1, 3, 3, 3, 1, 4, 0, 4, 0, 1, 0, 0, 4, 4, 0, 1, 2, 2, 2, 1, 4, 4, 2,\n",
              "        4, 0, 3, 1, 2, 0, 1, 3, 1, 2, 3, 1, 3, 4, 4, 1, 3, 0, 1, 0, 0, 2, 0, 1,\n",
              "        2, 3, 3, 1, 1, 0, 1, 3, 4, 3, 4, 2, 0, 2, 4, 4, 0, 4, 2, 3, 1, 0, 4, 2,\n",
              "        1, 4, 0, 2, 0, 1, 2, 0, 1, 1, 1, 1, 0, 3, 2, 3, 1, 4, 3, 3, 3, 2, 0, 0,\n",
              "        0, 3, 2, 0, 3, 4, 4, 4, 4, 3, 0, 4, 1, 3, 1, 0, 4, 3, 1, 0, 2, 0, 3, 4,\n",
              "        3, 1, 0, 1, 0, 3, 0, 2, 4, 2, 0, 2, 3, 4, 4, 0, 2, 0, 0, 1, 3, 0, 4, 2,\n",
              "        2, 3, 3, 4, 1, 3, 4, 4, 4, 0, 4, 1, 4, 3, 0, 1, 2, 2, 0, 2, 0, 0, 4, 1,\n",
              "        3, 0, 4, 1, 1, 3, 4, 1, 2, 4, 4, 3, 3, 0, 0, 2, 4, 3, 3, 0, 2, 0, 2, 0,\n",
              "        0, 1, 2, 4, 4, 3, 2, 3, 3, 0, 0, 0, 2, 1, 2, 0, 3, 2, 1, 0, 0, 4, 0, 3,\n",
              "        3, 2, 4, 0, 1, 1, 3, 1, 2, 1, 0, 0, 3, 3, 0, 2, 0, 0, 4, 3, 4, 0, 0, 2,\n",
              "        0, 4, 0, 1, 4, 4, 2, 0, 0, 2, 4, 2, 4, 0, 3, 3, 3, 2, 1, 2, 0, 3, 0, 0,\n",
              "        4, 4, 3, 2, 0, 3, 1, 2, 2, 3, 4, 3, 4, 3, 0, 3, 1, 0, 3, 4, 4, 2, 2, 1,\n",
              "        2, 1, 3, 0, 3, 3, 4, 0, 0, 4, 2, 3, 2, 0, 4, 4, 4, 0, 3, 4, 3, 3, 2, 3,\n",
              "        2, 2, 1, 2, 4, 3, 2, 3, 1, 1, 1, 4, 3, 3, 2, 1, 1, 0, 1, 2, 4, 0, 2, 4,\n",
              "        3, 0, 1, 3, 4, 4, 1, 3, 2, 4, 3, 2, 2, 3, 4, 0, 4, 0, 0, 0, 3, 4, 2, 4,\n",
              "        3, 2, 1, 4, 2, 0, 0, 0, 2, 4, 3, 0, 0, 0, 2, 3, 2, 1, 0, 0, 1, 2, 1, 2,\n",
              "        4, 2, 3, 3, 1, 1, 3, 1, 2, 3, 0, 2, 0, 2, 2, 0, 4, 4, 2, 2, 1, 3, 2, 2,\n",
              "        3, 3, 3, 1, 1, 4, 1, 0, 3, 1, 1, 1, 0, 3, 1, 3, 0, 1, 4, 4, 1, 0, 2, 0,\n",
              "        2, 2, 3, 1, 0, 1, 3, 3, 3, 2, 2, 1, 1, 3, 1, 1, 2, 0, 3, 0, 1, 3, 4, 3,\n",
              "        4, 1, 2, 3, 2, 4, 3, 3, 2, 0, 1, 4, 0, 2, 0, 0, 0, 3, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar relatório de classificação\n",
        "print(classification_report(y_test_tensor, predictions_w, target_names=emotions))"
      ],
      "metadata": {
        "id": "CHEuzmqofpOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29e8627-dddb-44e2-e1c4-80f0139161ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  aggressive       0.51      0.58      0.54       100\n",
            "    dramatic       0.50      0.45      0.47       100\n",
            "       happy       0.63      0.63      0.63       100\n",
            "    romantic       0.44      0.48      0.46       100\n",
            "         sad       0.58      0.51      0.54       100\n",
            "\n",
            "    accuracy                           0.53       500\n",
            "   macro avg       0.53      0.53      0.53       500\n",
            "weighted avg       0.53      0.53      0.53       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine-Tuning com HDC**"
      ],
      "metadata": {
        "id": "KgHtzHdoo66I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchhd\n",
        "!pip install binhd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzXuEp6oo9vB",
        "outputId": "acdf912c-bc92-4f6f-cae3-7998ae5555f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torchhd (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchhd\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting binhd\n",
            "  Downloading binhd-1.0.0a0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting torch-hd (from binhd)\n",
            "  Downloading torch_hd-5.8.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (from binhd) (0.0.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from binhd) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->binhd) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->binhd) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->binhd) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->binhd) (2025.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from torch-hd->binhd) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-hd->binhd) (1.15.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-hd->binhd) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-hd->binhd) (4.67.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from torch-hd->binhd) (3.1.5)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo->binhd) (2025.7.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->binhd) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torch-hd->binhd) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->torch-hd->binhd) (1.3.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->torch-hd->binhd) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-hd->binhd) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-hd->binhd) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-hd->binhd) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->torch-hd->binhd) (3.0.2)\n",
            "Downloading binhd-1.0.0a0-py3-none-any.whl (14 kB)\n",
            "Downloading torch_hd-5.8.4-py3-none-any.whl (360 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.0/361.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-hd, binhd\n",
            "Successfully installed binhd-1.0.0a0 torch-hd-5.8.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchhd\n",
        "from torchhd import embeddings\n",
        "\n",
        "from binhd.classifiers import BinHD\n",
        "from binhd.embeddings import ScatterCode"
      ],
      "metadata": {
        "id": "Lxwn_8NTK6RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definição de hiperparâmetros\n",
        "\n",
        "dimension = 1000\n",
        "num_levels = 100\n",
        "\n",
        "min_val = X_train_tensor.min().item()\n",
        "max_val = X_train_tensor.max().item()\n",
        "print(f\"Feature min: {min_val}, max: {max_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLCT-U7KN1ee",
        "outputId": "3ca479e8-2083-452a-87a8-69479b61821c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature min: 0.0, max: 5.7164740562438965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classe RecordEncoder com modificações referentes ao uso de cpu ou cuda\n",
        "class RecordEncoder(nn.Module):\n",
        "    def __init__(self, out_features, size, levels, low, high, device=None):\n",
        "        super(RecordEncoder, self).__init__()\n",
        "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.position = embeddings.Random(size, out_features, vsa=\"BSC\", dtype=torch.uint8)\n",
        "        self.value = ScatterCode(levels, out_features, low=low, high=high)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mover entrada para o device\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        sample_hv = torchhd.bind(self.position.weight, self.value(x))\n",
        "        sample_hv = torchhd.multiset(sample_hv)\n",
        "        return sample_hv"
      ],
      "metadata": {
        "id": "cx3xWLvJN2UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# codificação baseada em Record\n",
        "record_encode = RecordEncoder(dimension, X_train_tensor.shape[1], num_levels, min_val, max_val, device=device)\n",
        "record_encode = record_encode.to(device)\n",
        "\n",
        "X_train_tensor = X_train_tensor.to(device)\n",
        "y_train_tensor = y_train_tensor.to(device)\n",
        "\n",
        "X_test_tensor = X_test_tensor.to(device)\n",
        "y_test_tensor = y_test_tensor.to(device)"
      ],
      "metadata": {
        "id": "nbYCaelMPc3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ajustes com relação ao device na classe BinHD, pois alguns tensores criados pela classe eram armazenados em cpu\n",
        "class BinHD2(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_dimensions: int,\n",
        "        n_classes: int,\n",
        "        *,\n",
        "        epochs: int = 30,\n",
        "        device: torch.device = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device or torch.device('cpu')\n",
        "\n",
        "        self.n_dimensions = n_dimensions\n",
        "        self.n_classes = n_classes\n",
        "        self.epochs = epochs\n",
        "        self.classes_counter = torch.empty((n_classes, n_dimensions), device=self.device, dtype=torch.int8)\n",
        "        self.classes_hv = None\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self) -> None:\n",
        "        nn.init.zeros_(self.classes_counter)\n",
        "\n",
        "    def fit(self, input: Tensor, target: Tensor):\n",
        "        input = input.to(self.device)\n",
        "        target = target.to(self.device)\n",
        "        input = 2 * input - 1\n",
        "        self.classes_counter.index_add_(0, target, input)\n",
        "        self.classes_hv = self.classes_counter.clamp(min=0, max=1)\n",
        "\n",
        "    def fit_adapt(self, input: Tensor, target: Tensor):\n",
        "        for _ in range(self.epochs):\n",
        "            self.adapt(input, target)\n",
        "\n",
        "    def adapt(self, input: Tensor, target: Tensor):\n",
        "        input = input.to(self.device)\n",
        "        target = target.to(self.device)\n",
        "\n",
        "        pred = self.predict(input)\n",
        "        is_wrong = target != pred\n",
        "\n",
        "        if is_wrong.sum().item() == 0:\n",
        "            return\n",
        "\n",
        "        input = input[is_wrong]\n",
        "        input = 2 * input - 1\n",
        "        target = target[is_wrong]\n",
        "        pred = pred[is_wrong]\n",
        "\n",
        "        self.classes_counter.index_add_(0, target, input, alpha=1)\n",
        "        self.classes_counter.index_add_(0, pred, input, alpha=-1)\n",
        "        self.classes_hv = torch.where(self.classes_counter >= 0, 1, 0)\n",
        "\n",
        "    def forward(self, samples: Tensor) -> Tensor:\n",
        "        samples = samples.to(self.device)\n",
        "        response = torch.empty((self.n_classes, samples.shape[0]), dtype=torch.int8, device=self.device)\n",
        "\n",
        "        for i in range(self.n_classes):\n",
        "            response[i] = torch.sum(torch.bitwise_xor(samples, self.classes_hv[i]), dim=1)\n",
        "\n",
        "        return response.transpose_(0, 1)\n",
        "\n",
        "    def predict(self, samples: Tensor) -> Tensor:\n",
        "        samples = samples.to(self.device)\n",
        "        return torch.argmin(self(samples), dim=-1)\n"
      ],
      "metadata": {
        "id": "7CuwbpVu20Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bhd = BinHD2(dimension, num_classes)\n",
        "model_bhd.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    X_train_record = record_encode(X_train_tensor).to(device)\n",
        "    X_test_record = record_encode(X_test_tensor).to(device)\n",
        "\n",
        "    #X_train_record.is_cuda = True\n",
        "    #y_train_tensor.is_cuda = True\n",
        "    model_bhd.fit(X_train_record,y_train_tensor)\n",
        "\n",
        "    predictions_bhd = model_bhd.predict(X_test_record)"
      ],
      "metadata": {
        "id": "6TX92FnRN9k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar relatório de classificação\n",
        "print(classification_report(y_test_tensor.cpu(), predictions_bhd.cpu(), target_names=emotions))"
      ],
      "metadata": {
        "id": "YwIR9oX-fvV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45738ee7-4c9d-4a7a-bd09-f6884fb14bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  aggressive       0.19      0.18      0.19       100\n",
            "    dramatic       0.21      0.54      0.30       100\n",
            "       happy       0.20      0.09      0.12       100\n",
            "    romantic       0.21      0.20      0.21       100\n",
            "         sad       0.25      0.01      0.02       100\n",
            "\n",
            "    accuracy                           0.20       500\n",
            "   macro avg       0.21      0.20      0.17       500\n",
            "weighted avg       0.21      0.20      0.17       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parte 3: Análise Comparativa**"
      ],
      "metadata": {
        "id": "j-oAHORCoQXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "<tr>\n",
        "<td><b>Modelo</b></td>\n",
        "<td><b>Acurácia Geral</b></td>\n",
        "<td><b>Precisão Média</b></td>\n",
        "<td><b>Recall Médio</b></td>\n",
        "<td><b>F1-Score Médio</b></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><b>CNN</b></td>\n",
        "<td>93.00%</td>\n",
        "<td>92.80%</td>\n",
        "<td>92.80%</td>\n",
        "<td>92.80%</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><b>WiSARD</b></td>\n",
        "<td>53.00%</td>\n",
        "<td>53.20%</td>\n",
        "<td>53.00%</td>\n",
        "<td>53.80%</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><b>BinHD</b></td>\n",
        "<td>20.00%</td>\n",
        "<td>21.20%</td>\n",
        "<td>20.40%</td>\n",
        "<td>16.80%</td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "nlAPCuqSoIde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pela tabela comparativa, pode-se observar, de forma geral, que:\n",
        "\n",
        "**CNN:** Modelo com melhor desempenho. Apresentou altos e melhores valores para as métricas, indicando que se trata de um modelo com ótimo desempenho para a tarefa de classificação de imagens de spectrogramas.\n",
        "\n",
        "**WiSARD:** Modelo com desempenho mediado, com métricas significativamente inferiores à CNN, na faixa de 53%.\n",
        "\n",
        "**BinHD:** Modelo com pior desempenho, com métricas muito baixas e indicando que o modelo não conseguiu generalizar o problema para executar a tarefa de classificação.\n",
        "\n",
        "De forma mais específica:\n",
        "\n",
        "O **modelo CNN** se destaca o melhor desempenho para a classe \"happy\" e \"aggressive\", com todas as métricas acima de 92%. Além disso, os valores elevados de F1-Score indicam bom equilíbrio entre precisão e recall.\n",
        "\n",
        "O desempenho mediano do **modelo WiSARD**, com precisão e recall na faixa de 53%, indica que o modelo consegue capturar algumas características relevantes, porém não o suficiente para generalizar bem.\n",
        "\n",
        "As métricas muito baixas do **modelo BinHD** indicam que o modelo pode não ter capturado as características dos dados e, por isso, não consegue distinguir adequadamente as cinco classes da tarefa. Este problema pode ocorrer devido a falhas nos ajustes do treinamento.\n",
        "\n"
      ],
      "metadata": {
        "id": "D7cP_0-brbh1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}